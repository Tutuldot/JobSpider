{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (4.10.0)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from selenium) (1.26.15)\n",
      "Requirement already satisfied: trio~=0.17 in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from selenium) (0.22.2)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from selenium) (0.10.3)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: attrs>=20.1.0 in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from trio~=0.17->selenium) (22.2.0)\n",
      "Requirement already satisfied: sortedcontainers in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: idna in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: outcome in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in /home/gitpod/.pyenv/versions/3.11.1/lib/python3.11/site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.1.2)\n",
      "Requirement already satisfied: wsproto>=0.14 in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in /workspace/.pyenv_mirror/user/current/lib/python3.11/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'selenium'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# imports\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mselenium\u001b[39;00m \u001b[39mimport\u001b[39;00m webdriver\n\u001b[1;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mselenium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwebdriver\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mchrome\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mservice\u001b[39;00m \u001b[39mimport\u001b[39;00m Service\n\u001b[1;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mselenium\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mwebdriver\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39msupport\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mui\u001b[39;00m \u001b[39mimport\u001b[39;00m WebDriverWait\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'selenium'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import time\n",
    "# chrome driver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "#edge driver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "import os\n",
    "from supabase import create_client, Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# this function will make an array unique\n",
    "def getnumbers(str):\n",
    "    numbers_only = re.sub(\"[^0-9]\", \"\", str)\n",
    "    return numbers_only\n",
    "\n",
    "def unique(list1):\n",
    " \n",
    "    unique_list = []\n",
    " \n",
    "    for x in list1:\n",
    "        if x.text not in unique_list and str(x.text) != '' :\n",
    "            lstr = str(x.text).strip()\n",
    "            unique_list.append(lstr)\n",
    "    return unique_list\n",
    "\n",
    "def getTitleAndVerified(headerList):\n",
    "    \n",
    "    jobTitle = headerList[0].title()\n",
    "    links = [r for r in headerList if \"Verified\" in r]\n",
    "    isVerified = 'Not Verified'\n",
    "    if len(links) > 0:\n",
    "        isVerified = \"Verified\"\n",
    "        \n",
    "    return jobTitle,isVerified\n",
    "\n",
    "def getJobDetails(soup):\n",
    "     # job details\n",
    "    jDetails = soup.find_all(\"ul\", {\"class\": \"job-posting-brief\"}) \n",
    "    jDetailsList =  jDetails[0].find_all('li')\n",
    "\n",
    "    datePosted = soup.find_all(\"span\", {\"property\": \"datePosted\"})[0].text.strip()\n",
    "    addressLocality = soup.find_all(\"span\", {\"property\": \"addressLocality\"})[0].text.strip()\n",
    "    addressRegion = soup.find_all(\"span\", {\"property\": \"addressRegion\"})[0].text.strip()\n",
    "    workHours = soup.find_all(\"span\", {\"property\": \"workHours\"})[0].text.strip()\n",
    "    hourlySalary = soup.find_all(\"span\", {\"property\": \"minValue\"})[0].text.strip()\n",
    "    employmentType = soup.find_all(\"span\", {\"property\": \"employmentType\"})[0].text.strip()\n",
    "    #specialCommitments = soup.find_all(\"span\", {\"property\": \"specialCommitments\"})[0].text.strip()\n",
    "    \n",
    "    return addressLocality, addressRegion, workHours, hourlySalary, employmentType, datePosted\n",
    "    \n",
    "def getJobFunction(soup):\n",
    "    rDetails = soup.find_all(\"div\", {\"id\": \"comparisonchart\"}) \n",
    "    languages = soup.find_all(\"p\", {\"property\": \"qualification\"})[0].text.strip()\n",
    "    educationRequirements = soup.find_all(\"ul\", {\"property\": \"educationRequirements qualification\"})[0].text.strip().replace('\\n', ' ').replace('\\r','')\n",
    "    xpQualification = soup.find_all(\"p\", {\"property\": \"experienceRequirements qualification\"})[0].text.strip().replace('\\n', ' ').replace('\\r','')\n",
    "    responsibilitiesMock = soup.find_all(\"div\", {\"property\": \"responsibilities\"})[0]\n",
    "    r1 = responsibilitiesMock.find('h3')\n",
    "    r2 = responsibilitiesMock.find('h4')\n",
    "    r1.replaceWith('')\n",
    "    r2.replaceWith('')\n",
    "    responsibilitiesMock = responsibilitiesMock.text\n",
    "    \n",
    "    return languages, educationRequirements, xpQualification,responsibilitiesMock\n",
    "\n",
    "def checkValidMail(email):\n",
    "    regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b'\n",
    "    if(re.fullmatch(regex, email)):\n",
    "        return True\n",
    " \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def processPerLink(lnk, baseURL = \"https://www.jobbank.gc.ca\"):\n",
    "\n",
    "    testURL = baseURL + lnk\n",
    "    print(testURL)\n",
    "    driver.get(testURL)\n",
    "    time.sleep(15)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    type(soup)\n",
    "    # find Job Name and \n",
    "    h1Title = soup.find_all(\"h1\", {\"class\": \"title\"})\n",
    "    titleSpan = h1Title[0].find_all('span')\n",
    "    titleSpan = unique(titleSpan)\n",
    "    jobTitle, isVerified =  getTitleAndVerified(titleSpan)\n",
    "    #print(jobTitle,isVerified)\n",
    "    \n",
    "    addressLocality, addressRegion, workHours, hourlySalary, employmentType, datePosted = getJobDetails(soup)\n",
    "    #print(addressLocality, addressRegion, workHours, hourlySalary, employmentType)\n",
    "    \n",
    "    #role details\n",
    "    languages, educationRequirements, xpQualification,responsibilitiesMock = getJobFunction(soup)\n",
    "    #print(languages, educationRequirements, xpQualification,responsibilitiesMock)\n",
    "    # view email details\n",
    "    looper = 1\n",
    "    counter = 0\n",
    "    # first check\n",
    "    checkHowToApplyDiv = soup.find_all(\"div\", {\"id\": \"howtoapply\"})\n",
    "    if len(checkHowToApplyDiv) > 0: \n",
    "        looper = 0\n",
    "    while looper == 1:\n",
    "        counter = counter + 1\n",
    "        if counter >= 300:\n",
    "            looper = 0\n",
    "        driver.find_element(By.ID,'applynowbutton').click()\n",
    "        time.sleep(2)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        checkHowToApplyDiv = soup.find_all(\"div\", {\"id\": \"howtoapply\"})\n",
    "        if len(checkHowToApplyDiv) > 0: \n",
    "            looper = 0\n",
    "\n",
    "    howToApply = soup.find_all(\"div\", {\"id\": \"howtoapply\"})[0]\n",
    "    possibleEmailList = soup.find_all('a') \n",
    "    email = ''\n",
    "    for s in possibleEmailList:\n",
    "        if checkValidMail(s.text):\n",
    "            email = s.text\n",
    "            \n",
    "    print(email)\n",
    "    return {'jobTitle' : jobTitle,\n",
    "            'datePosted' : datePosted,\n",
    "            'isVerified' : isVerified,\n",
    "            'addressLocality' : addressLocality, \n",
    "            'addressRegion' : addressRegion,\n",
    "            'workHours' : workHours, \n",
    "            'hourlySalary' : hourlySalary,\n",
    "            'employmentType' : employmentType,\n",
    "            'languages' : languages, \n",
    "            'educationRequirements' : educationRequirements,\n",
    "            'xpQualification' : xpQualification,\n",
    "            'Responsibilities' : responsibilitiesMock.replace('\\n',' '),\n",
    "            'email' : email\n",
    "           }\n",
    "    \n",
    "def runJob(url,reload_browser):\n",
    "    if reload_browser:\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        chrome_options.add_argument( '--disable-blink-features=AutomationControlled' )\n",
    "        chrome_options.add_argument('--proxy-server=%s' % '10.91.104.10' + \":\" + '80')\n",
    "        driver = webdriver.Chrome(options=chrome_options,service_args=[\"--verbose\"])\n",
    "\n",
    "        time.sleep(15)\n",
    "    \n",
    "    ## edge\n",
    "    #driver = webdriver.Edge()\n",
    "    #edge_options = webdriver.EdgeOptions()\n",
    "    #edge_options.add_argument('--proxy-server=%s' % '10.91.104.10' + \":\" + '80')\n",
    "    #driver = webdriver.Edge(options=chrome_options)\n",
    "\n",
    "    #driver.get('https://bing.com')\n",
    "   \n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(15)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    type(soup)\n",
    "    all_links = soup.find_all(\"a\")\n",
    "    res = [link.get('href') for link in all_links]\n",
    "    links = [r for r in res if \"jobposting\" in r]\n",
    "    for l in links:\n",
    "        print(processPerLink(l))\n",
    "# https://www.browserstack.com/guide/web-scraping-using-selenium-python\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# execution sample \n",
    " runJob('https://www.jobbank.gc.ca/jobsearch/jobsearch?searchstring=data&locationstring=&fglo=1&sort=M',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tests\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument( '--disable-blink-features=AutomationControlled' )\n",
    "    chrome_options.add_argument('--proxy-server=%s' % '10.91.104.10' + \":\" + '80')\n",
    "    \n",
    "    #chrome_options.add_argument(\"--headless\")\n",
    "    #chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    #chrome_options.add_argument(\"--no-sandbox\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options,service_args=[\"--verbose\"])\n",
    "    #time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ## edge\n",
    "    #driver = webdriver.Edge()\n",
    "    #edge_options = webdriver.EdgeOptions()\n",
    "    #edge_options.add_argument('--proxy-server=%s' % '10.91.104.10' + \":\" + '80')\n",
    "    #driver = webdriver.Edge(options=chrome_options)\n",
    "\n",
    "    #driver.get('https://bing.com')\n",
    "\n",
    "\n",
    "    #driver.get('https://www.jobbank.gc.ca/jobsearch/jobsearch?searchstring=clean&locationstring=&fglo=1&sort=M')\n",
    "    #time.sleep(15)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    type(soup)\n",
    "    all_links = soup.find_all(\"a\")\n",
    "    res = [link.get('href') for link in all_links]\n",
    "    links = [r for r in res if \"jobposting\" in r]\n",
    "    #for l in links:\n",
    "        #print(processPerLink(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = soup.find_all(\"article\")\n",
    "joblinks = []\n",
    "for articles_a in articles:\n",
    "    articles_a = articles[0].find('a')\n",
    "    url = articles_a.get('href')\n",
    "    source = articles_a.find_all(\"li\", {\"class\": \"source\"})\n",
    "    jobsource = source[0].find('span').text\n",
    "    jobid = getnumbers(source[0].text)\n",
    "    jobinfocontainer = articles_a.find_all(\"span\", {\"class\": \"noctitle\"})\n",
    "    jc = jobinfocontainer[0].text.replace(\"\\n\", \";\").replace(\"\\t\",\";\")\n",
    "    jc_final = [x for x in jc.split(';') if len(x) > 0]\n",
    "    job_title = jc_final[0]\n",
    "    job_verified = jc_final[1]\n",
    "    \n",
    "    joblinks.append({'url' : url, 'source': jobsource, 'jobid': jobid,'job_title':job_title,'job_verified':job_verified })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url: str = \"https://prdanvztefttoqaqozob.supabase.co\"\n",
    "key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InByZGFudnp0ZWZ0dG9xYXFvem9iIiwicm9sZSI6ImFub24iLCJpYXQiOjE2ODk3NTcxNDcsImV4cCI6MjAwNTMzMzE0N30.hvnMO56CGgOLI0lHiAuFAhTM95ul1baO18VNzooznTo\"\n",
    "supabase: Client = create_client(url, key)\n",
    "response = supabase.table('countries').select(\"*\").execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
