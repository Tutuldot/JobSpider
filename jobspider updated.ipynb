{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import codecs\n",
    "import re\n",
    "import time\n",
    "# chrome driver\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "#edge driver\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "\n",
    "from fake_useragent import UserAgent\n",
    "import os\n",
    "from supabase import create_client, Client\n",
    "\n",
    "# https://www.jobbank.gc.ca/jobsearch/jobsearch?fage=2&fglo=1&page=3&sort=M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions\n",
    "\n",
    "# this function will make an array unique\n",
    "def getnumbers(str):\n",
    "    numbers_only = re.sub(\"[^0-9]\", \"\", str)\n",
    "    return numbers_only\n",
    "\n",
    "def unique(list1):\n",
    " \n",
    "    unique_list = []\n",
    " \n",
    "    for x in list1:\n",
    "        if x.text not in unique_list and str(x.text) != '' :\n",
    "            lstr = str(x.text).strip()\n",
    "            unique_list.append(lstr)\n",
    "    return unique_list\n",
    "\n",
    "def getTitleAndVerified(headerList):\n",
    "    \n",
    "    jobTitle = headerList[0].title()\n",
    "    links = [r for r in headerList if \"Verified\" in r]\n",
    "    isVerified = 'Not Verified'\n",
    "    if len(links) > 0:\n",
    "        isVerified = \"Verified\"\n",
    "        \n",
    "    return jobTitle,isVerified\n",
    "\n",
    "def getJobDetails(soup):\n",
    "     # job details\n",
    "    jDetails = soup.find_all(\"ul\", {\"class\": \"job-posting-brief\"}) \n",
    "    jDetailsList =  jDetails[0].find_all('li')\n",
    "\n",
    "    datePosted = soup.find_all(\"span\", {\"property\": \"datePosted\"})[0].text.strip()\n",
    "    addressLocality = soup.find_all(\"span\", {\"property\": \"addressLocality\"})[0].text.strip()\n",
    "    addressRegion = soup.find_all(\"span\", {\"property\": \"addressRegion\"})[0].text.strip()\n",
    "    workHours = soup.find_all(\"span\", {\"property\": \"workHours\"})[0].text.strip()\n",
    "    hourlySalary = soup.find_all(\"span\", {\"property\": \"minValue\"})[0].text.strip()\n",
    "    employmentType = soup.find_all(\"span\", {\"property\": \"employmentType\"})[0].text.strip()\n",
    "    #specialCommitments = soup.find_all(\"span\", {\"property\": \"specialCommitments\"})[0].text.strip()\n",
    "    \n",
    "    return addressLocality, addressRegion, workHours, hourlySalary, employmentType, datePosted\n",
    "    \n",
    "def getJobFunction(soup):\n",
    "    rDetails = soup.find_all(\"div\", {\"id\": \"comparisonchart\"}) \n",
    "    languages = soup.find_all(\"p\", {\"property\": \"qualification\"})[0].text.strip()\n",
    "    educationRequirements = soup.find_all(\"ul\", {\"property\": \"educationRequirements qualification\"})[0].text.strip().replace('\\n', ' ').replace('\\r','')\n",
    "    xpQualification = soup.find_all(\"p\", {\"property\": \"experienceRequirements qualification\"})[0].text.strip().replace('\\n', ' ').replace('\\r','')\n",
    "    responsibilitiesMock = soup.find_all(\"div\", {\"property\": \"responsibilities\"})[0]\n",
    "    r1 = responsibilitiesMock.find('h3')\n",
    "    r2 = responsibilitiesMock.find('h4')\n",
    "    r1.replaceWith('')\n",
    "    r2.replaceWith('')\n",
    "    responsibilitiesMock = responsibilitiesMock.text\n",
    "    \n",
    "    return languages, educationRequirements, xpQualification,responsibilitiesMock\n",
    "\n",
    "def checkValidMail(email):\n",
    "    regex = r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,7}\\b'\n",
    "    if(re.fullmatch(regex, email)):\n",
    "        return True\n",
    " \n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "def processPerLink(lnk, baseURL = \"https://www.jobbank.gc.ca\"):\n",
    "\n",
    "    testURL = baseURL + lnk\n",
    "    print(testURL)\n",
    "    driver.get(testURL)\n",
    "    time.sleep(15)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    type(soup)\n",
    "    # find Job Name and \n",
    "    h1Title = soup.find_all(\"h1\", {\"class\": \"title\"})\n",
    "    titleSpan = h1Title[0].find_all('span')\n",
    "    titleSpan = unique(titleSpan)\n",
    "    jobTitle, isVerified =  getTitleAndVerified(titleSpan)\n",
    "    #print(jobTitle,isVerified)\n",
    "    \n",
    "    addressLocality, addressRegion, workHours, hourlySalary, employmentType, datePosted = getJobDetails(soup)\n",
    "    #print(addressLocality, addressRegion, workHours, hourlySalary, employmentType)\n",
    "    \n",
    "    #role details\n",
    "    languages, educationRequirements, xpQualification,responsibilitiesMock = getJobFunction(soup)\n",
    "    #print(languages, educationRequirements, xpQualification,responsibilitiesMock)\n",
    "    # view email details\n",
    "    looper = 1\n",
    "    counter = 0\n",
    "    # first check\n",
    "    checkHowToApplyDiv = soup.find_all(\"div\", {\"id\": \"howtoapply\"})\n",
    "    if len(checkHowToApplyDiv) > 0: \n",
    "        looper = 0\n",
    "    while looper == 1:\n",
    "        counter = counter + 1\n",
    "        if counter >= 300:\n",
    "            looper = 0\n",
    "        driver.find_element(By.ID,'applynowbutton').click()\n",
    "        time.sleep(2)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        checkHowToApplyDiv = soup.find_all(\"div\", {\"id\": \"howtoapply\"})\n",
    "        if len(checkHowToApplyDiv) > 0: \n",
    "            looper = 0\n",
    "\n",
    "    howToApply = soup.find_all(\"div\", {\"id\": \"howtoapply\"})[0]\n",
    "    possibleEmailList = soup.find_all('a') \n",
    "    email = ''\n",
    "    for s in possibleEmailList:\n",
    "        if checkValidMail(s.text):\n",
    "            email = s.text\n",
    "            \n",
    "    print(email)\n",
    "    return {'jobTitle' : jobTitle,\n",
    "            'datePosted' : datePosted,\n",
    "            'isVerified' : isVerified,\n",
    "            'addressLocality' : addressLocality, \n",
    "            'addressRegion' : addressRegion,\n",
    "            'workHours' : workHours, \n",
    "            'hourlySalary' : hourlySalary,\n",
    "            'employmentType' : employmentType,\n",
    "            'languages' : languages, \n",
    "            'educationRequirements' : educationRequirements,\n",
    "            'xpQualification' : xpQualification,\n",
    "            'Responsibilities' : responsibilitiesMock.replace('\\n',' '),\n",
    "            'email' : email\n",
    "           }\n",
    "    \n",
    "def runJob(url,reload_browser):\n",
    "    if reload_browser:\n",
    "        chrome_options = webdriver.ChromeOptions()\n",
    "        chrome_options.add_argument( '--disable-blink-features=AutomationControlled' )\n",
    "       \n",
    "        driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "        time.sleep(15)\n",
    "    \n",
    "    ## edge\n",
    "    #driver = webdriver.Edge()\n",
    "    #edge_options = webdriver.EdgeOptions()\n",
    "    #edge_options.add_argument('--proxy-server=%s' % '10.91.104.10' + \":\" + '80')\n",
    "    #driver = webdriver.Edge(options=chrome_options)\n",
    "\n",
    "    #driver.get('https://bing.com')\n",
    "   \n",
    "\n",
    "    driver.get(url)\n",
    "    time.sleep(15)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    type(soup)\n",
    "    all_links = soup.find_all(\"a\")\n",
    "    res = [link.get('href') for link in all_links]\n",
    "    links = [r for r in res if \"jobposting\" in r]\n",
    "    for l in links:\n",
    "        print(processPerLink(l))\n",
    "# https://www.browserstack.com/guide/web-scraping-using-selenium-python\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "argument of type 'NoneType' is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# execution sample \u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mrunJob\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://www.jobbank.gc.ca/jobsearch/jobsearch?searchstring=data&locationstring=&fglo=1&sort=M\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[5], line 154\u001b[0m, in \u001b[0;36mrunJob\u001b[1;34m(url, reload_browser)\u001b[0m\n\u001b[0;32m    152\u001b[0m all_links \u001b[38;5;241m=\u001b[39m soup\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    153\u001b[0m res \u001b[38;5;241m=\u001b[39m [link\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m link \u001b[38;5;129;01min\u001b[39;00m all_links]\n\u001b[1;32m--> 154\u001b[0m links \u001b[38;5;241m=\u001b[39m [r \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m res \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjobposting\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m]\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m links:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28mprint\u001b[39m(processPerLink(l))\n",
      "\u001b[1;31mTypeError\u001b[0m: argument of type 'NoneType' is not iterable"
     ]
    }
   ],
   "source": [
    "# execution sample \n",
    "runJob('https://www.jobbank.gc.ca/jobsearch/jobsearch?searchstring=data&locationstring=&fglo=1&sort=M',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "    url = 'https://www.jobbank.gc.ca/jobsearch/jobsearch?searchstring=data&locationstring=&fglo=1&sort=M'\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    chrome_options.add_argument( '--disable-blink-features=AutomationControlled' )\n",
    "       \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "\n",
    "\n",
    "   \n",
    "\n",
    "    driver.get(url)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "type(soup)\n",
    "all_links = soup.find_all(\"a\")\n",
    "res = [link.get('href') for link in all_links]\n",
    "links = [r for r in res if \"jobposting\" in r]\n",
    "#for l in links:\n",
    "#    print(processPerLink(l))\n",
    "lnk = links[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.jobbank.gc.ca/jobsearch/jobposting/42286678?source=searchresults\n"
     ]
    }
   ],
   "source": [
    "    testURL =  \"https://www.jobbank.gc.ca\" + lnk\n",
    "    print(testURL)\n",
    "    driver.get(testURL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'html.parser')\n",
    "    type(soup)\n",
    "    # find Job Name and \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Litigation Legal Assistant Not Verified\n"
     ]
    }
   ],
   "source": [
    "    h1Title = soup.find_all(\"h1\", {\"class\": \"title\"})\n",
    "    titleSpan = h1Title[0].find_all('span')\n",
    "    titleSpan = unique(titleSpan)\n",
    "    jobTitle, isVerified =  getTitleAndVerified(titleSpan)\n",
    "    print(jobTitle,isVerified)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toronto ON 35 hours per week 70,000 Permanent employmentFull time\n",
      "English No degree, certificate or diploma 5 years or more \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Schedule and confirm appointments\n",
      "\n",
      "\n",
      "Maintain filing system\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    addressLocality, addressRegion, workHours, hourlySalary, employmentType, datePosted = getJobDetails(soup)\n",
    "    print(addressLocality, addressRegion, workHours, hourlySalary, employmentType)\n",
    "    \n",
    "    #role details\n",
    "    languages, educationRequirements, xpQualification,responsibilitiesMock = getJobFunction(soup)\n",
    "    print(languages, educationRequirements, xpQualification,responsibilitiesMock)\n",
    "    # view email details\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info@hiringpartner.ca\n"
     ]
    }
   ],
   "source": [
    "    looper = 1\n",
    "    counter = 0\n",
    "    # first check\n",
    "    checkHowToApplyDiv = soup.find_all(\"div\", {\"id\": \"howtoapply\"})\n",
    "    if len(checkHowToApplyDiv) > 0: \n",
    "        looper = 0\n",
    "    while looper == 1:\n",
    "        counter = counter + 1\n",
    "        if counter >= 300:\n",
    "            looper = 0\n",
    "        driver.find_element(By.ID,'applynowbutton').click()\n",
    "        time.sleep(2)\n",
    "        page_source = driver.page_source\n",
    "        soup = BeautifulSoup(page_source, 'html.parser')\n",
    "        checkHowToApplyDiv = soup.find_all(\"div\", {\"id\": \"howtoapply\"})\n",
    "        if len(checkHowToApplyDiv) > 0: \n",
    "            looper = 0\n",
    "\n",
    "    howToApply = soup.find_all(\"div\", {\"id\": \"howtoapply\"})[0]\n",
    "    possibleEmailList = soup.find_all('a') \n",
    "    email = ''\n",
    "    for s in possibleEmailList:\n",
    "        if checkValidMail(s.text):\n",
    "            email = s.text\n",
    "            \n",
    "    print(email)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    ## edge\n",
    "    #driver = webdriver.Edge()\n",
    "    #edge_options = webdriver.EdgeOptions()\n",
    "    #edge_options.add_argument('--proxy-server=%s' % '10.91.104.10' + \":\" + '80')\n",
    "    #driver = webdriver.Edge(options=chrome_options)\n",
    "\n",
    "    #driver.get('https://bing.com')\n",
    "\n",
    "\n",
    "    #driver.get('https://www.jobbank.gc.ca/jobsearch/jobsearch?searchstring=clean&locationstring=&fglo=1&sort=M')\n",
    "    #time.sleep(15)\n",
    "    page_source = driver.page_source\n",
    "    soup = BeautifulSoup(page_source, 'lxml')\n",
    "    type(soup)\n",
    "    all_links = soup.find_all(\"a\")\n",
    "    res = [link.get('href') for link in all_links]\n",
    "    links = [r for r in res if \"jobposting\" in r]\n",
    "    #for l in links:\n",
    "        #print(processPerLink(l))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = soup.find_all(\"article\")\n",
    "joblinks = []\n",
    "for articles_a in articles:\n",
    "    articles_a = articles[0].find('a')\n",
    "    url = articles_a.get('href')\n",
    "    source = articles_a.find_all(\"li\", {\"class\": \"source\"})\n",
    "    jobsource = source[0].find('span').text\n",
    "    jobid = getnumbers(source[0].text)\n",
    "    jobinfocontainer = articles_a.find_all(\"span\", {\"class\": \"noctitle\"})\n",
    "    jc = jobinfocontainer[0].text.replace(\"\\n\", \";\").replace(\"\\t\",\";\")\n",
    "    jc_final = [x for x in jc.split(';') if len(x) > 0]\n",
    "    job_title = jc_final[0]\n",
    "    job_verified = jc_final[1]\n",
    "    \n",
    "    joblinks.append({'url' : url, 'source': jobsource, 'jobid': jobid,'job_title':job_title,'job_verified':job_verified })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url: str = \"https://prdanvztefttoqaqozob.supabase.co\"\n",
    "key: str = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJzdXBhYmFzZSIsInJlZiI6InByZGFudnp0ZWZ0dG9xYXFvem9iIiwicm9sZSI6ImFub24iLCJpYXQiOjE2ODk3NTcxNDcsImV4cCI6MjAwNTMzMzE0N30.hvnMO56CGgOLI0lHiAuFAhTM95ul1baO18VNzooznTo\"\n",
    "supabase: Client = create_client(url, key)\n",
    "response = supabase.table('countries').select(\"*\").execute()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
